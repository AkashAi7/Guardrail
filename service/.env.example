# Guardrail Service Configuration - Hybrid Edition

# Server Configuration
PORT=3000

# Provider Configuration
# Mode: 'auto' (auto-detect), 'copilot' (force Copilot), or 'byok' (force BYOK)
PROVIDER_MODE=auto

# Copilot SDK Configuration (when using Copilot provider)
COPILOT_MODEL=gpt-4           # Model to use with Copilot
ANALYSIS_TIMEOUT_MS=10000     # Timeout for LLM analysis (milliseconds)

# BYOK (Bring Your Own Key) Configuration
# Automatically detected based on which key is present

# Option 1: OpenAI
# OPENAI_API_KEY=sk-your-key-here
# BYOK_MODEL=gpt-4o

# Option 2: Anthropic
# ANTHROPIC_API_KEY=sk-ant-your-key-here
# BYOK_MODEL=claude-3-5-sonnet-20241022

# Option 3: Azure OpenAI
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_KEY=your-azure-key
# AZURE_OPENAI_DEPLOYMENT=gpt-4-deployment-name

# Analysis Configuration
MAX_FILE_SIZE_MB=5            # Maximum file size to analyze
ENABLE_CACHING=false          # Enable response caching (future feature)

# Governance Rules
GOVERNANCE_PATH=../governance # Path to governance markdown files

# ============================================
# HYBRID SETUP GUIDE
# ============================================
# 
# AUTO MODE (Recommended):
#   - Leave PROVIDER_MODE=auto
#   - If you have GitHub Copilot in VS Code: Works immediately (zero cost)
#   - If you don't have Copilot: Add API key above
#
# COPILOT MODE:
#   - Set PROVIDER_MODE=copilot
#   - Requires GitHub Copilot subscription
#   - No API keys needed
#   - Cost: Included in Copilot subscription
#
# BYOK MODE:
#   - Set PROVIDER_MODE=byok
#   - Add one of the API keys above
#   - Cost: Pay-as-you-go to your provider
#   - Estimated: $0.03 per 1K tokens
#
